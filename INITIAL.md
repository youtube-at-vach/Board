--- 

# CLIベースAI討論プラットフォーム計画書（司会進行付きバージョン）

## 1. プロジェクト概要・目的

### 概要

* 複数のAI（LLM）をCLI環境で呼び出し、主題に対して討論を行う。
* 特徴的なのは「**司会者AI**」が各ラウンドで「**誰に話を振るか**」を決定し、討論を進行する形式。

### 目的

* 多人数討論において自然なテーマ遷移・焦点化を実現。
* AI同士の意見対立、補足、応答などをよりダイナミックに観察できる。

---

## 2. 特徴

*   **CLI中心**: 軽量で操作しやすく、Web環境不要。
*   **司会者AI制御**: 会話の流れを制御する進行役を導入。
*   **AI間インタラクション**: 司会者が「誰に話を聞くか」選択、AIはその指示に基づいて応答。
*   **多モデル対応**: 各AIに別のLLMを割り当て可能。
*   **人格設定**: 各エージェントに視点・立場を設定可能。
*   **応答長制御**: 各AIの応答の長さを設定可能。
*   **デバッグモード**: コマンドライン引数でデバッグ出力を制御。
*   **視認性の向上**: 討論の流れを色分けして表示。
*   **ラウンド要約**: 各ラウンド終了時に司会者が討論内容を要約（オプション）。

---

## 3. 討論の進行構造（更新版）

### 進行フロー

1.  主題をCLIで入力または選択。
2.  初手（第一ラウンド）は司会者が話題を提示し、任意の一人に意見を求める。
3.  以降、毎ラウンドで司会者が次に発言すべきAIを選択し、そのAIは前の発言を踏まえて発言。
4.  各発言は履歴に記録され、最終ラウンド終了後にログを保存。
5.  各ラウンド終了時、オプションで司会者が討論内容を要約。

---

## 4. 設定ファイル構成（更新）

### `config/agents.yaml` 例

```yaml
moderator:
  name: Moderator
  model: gpt-3.5-turbo
  persona: "公正で冷静な司会者として、話を円滑に進める。各AIの意見を適切に引き出す。"
  response_length: short

agents:
  - name: AI-A
    model: gpt-3.5-turbo
    persona: "技術的に保守的な立場を取るAI"
    response_length: medium
  - name: AI-B
    model: gpt-3.5-turbo
    persona: "革新的で急進的な意見を好むAI"
    response_length: medium
  - name: AI-C
    model: gemini-1.5-flash
    persona: "バランスの取れた、客観的な分析を得意とするAI"
    response_length: medium
```

### `config/models.yaml` 例

```yaml
models:
  gpt-3.5-turbo:
    api: openai
    name: gpt-3.5-turbo
  gemini-1.5-flash:
    api: gemini
    name: gemini-1.5-flash
  deepseek-chat:
    api: deepseek
    name: deepseek-chat
```

---

## 5. 使用例（更新）

```bash
$ python main.py --topic "AIによる教育の未来" --rounds 6 --summarize-rounds --debug
```

### 出力例（抜粋）

```
[Round 1] Moderator:
> 本日は「AIによる教育の未来」について議論します。
> まずは AI-B さん、あなたの意見をお聞かせください。

[AI-B]:
> 私はAIによる個別指導がすでに現実的であり、教育の未来は完全にパーソナライズされるべきだと考えます...

[Round 2] Moderator:
> 興味深い視点ですね。それに対して、AI-C さんのご意見は？

[AI-C]:
> 確かに個別最適化には可能性がありますが、それは社会性や集団での学びを犠牲にするリスクもあります...

[Moderator Summary]:
> これまでの議論では、AIによる個別指導の可能性と、それがもたらす社会性や集団学習への影響が議論されました。
...
```

---

## 6. 実装ロジック（概要）

*   `main.py`:
    *   全体制御。トピック入力 → 設定読み込み → 討論ループ実行。
    *   コマンドライン引数（`--debug`, `--summarize-rounds`）の処理。
*   `moderator_engine.py`:
    *   現在までの発言ログをもとに「次に誰に話を振るか」を決定し、質問を生成。
    *   司会者自身が選択理由と質問を発言。
    *   討論内容の要約機能を実装。
*   `agent_engine.py`:
    *   各AIの人格とモデル情報を管理し、プロンプトを構築してAPI呼び出し。
*   `state_tracker.py`:
    *   各ラウンドのログを保存・参照用に整形。
*   `llm_api.py`:
    *   OpenAI (gpt-3.5-turbo) および Gemini (gemini-1.5-flash) のAPIラッパーを実装。
    *   DeepSeekのモックAPIを実装。
    *   応答長制御（`max_tokens`とプロンプト指示）を実装。
*   `utils.py`:
    *   デバッグ出力制御とANSIカラーコードを定義。

---

## 7. ログ保存形式（例）

### `logs/education_debate_20250709.jsonl`

```json
{"round": 1, "speaker": "Moderator", "text": "AI-B さん、まずお願いします"}
{"round": 1, "speaker": "AI-B", "text": "教育の未来はAIによって..."}
{"round": 2, "speaker": "Moderator", "text": "その意見に対して AI-C さん、どう思いますか？"}
{"round": 2, "speaker": "AI-C", "text": "確かに...しかし..."}
```

---

## 8. 司会者用プロンプトテンプレート（例）

```text
あなたは討論の司会者です。以下の主題と過去の発言を元に、次に発言すべき人物を選び、簡潔な理由を添えてその人物に話を振ってください。

利用可能な発言者: {available_agents}

主題: {topic}

過去の発言:
{history}

現在のラウンド: {current_round}

回答形式:
<呼びかけ>（例：「次は AI-A さん、お願いします」）
<簡単な説明>（例：「先ほどの意見に技術的な補足が必要だと感じました」）
<質問>（例：「AIが教育に与える影響について、具体的な事例を挙げていただけますか？」）
```

---

## 9. 利点

*   討論の流れが自然になり、脱線しにくい。
*   AI人格ごとの観点が交差・対立・補完しやすくなる。
*   複数モデルを交互ではなく**意図的に選択**できる柔軟性。
*   討論の要点を把握しやすくなる。

---

## 10. 未実装・将来拡張（案）

*   **DeepSeek APIの実装**: 現在はモックAPIを使用。
*   **人間参加型モード**: CLIユーザーが途中で割り込んで発言可能に。
*   **偏った司会**: 司会者が中立以外の「偏った司会」になるバリエーション（例：議論を煽る、意見を偏らせる）。
*   **リアルタイム視覚化モード**: ログをツリー状に視覚化。
*   **より堅牢なエラーハンドリング**: API呼び出しやLLM応答のパースにおける詳細なエラー処理。
*   **より洗練されたエージェント選択ロジック**: 現在の単純な正規表現やサイクリング以上の、複雑な議論状況に応じたエージェント選択。

---

以上が、**司会者AIを含む構成に対応した最新版の討論設計草案**になります。